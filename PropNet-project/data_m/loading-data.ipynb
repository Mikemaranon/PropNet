{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regresion Model: Analysis of house prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE DATASET\n",
    "we first load the dataset and make the next moves:\n",
    "- `check null values`: this is really important to know which columns wont give us enough information\n",
    "- `drop columns with high null-values rate`: if the null value rate is bigger than 5%, we drop the collumn because it wont give us enough information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASET\n",
    "df = pd.read_csv(\"csv_files/01_original_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasVnrArea      0.547945\n",
      "BsmtQual        2.534247\n",
      "BsmtCond        2.534247\n",
      "BsmtExposure    2.602740\n",
      "BsmtFinType1    2.534247\n",
      "BsmtFinType2    2.602740\n",
      "Electrical      0.068493\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SEE PROPORTION OF NULL VALUES FOR EACH COLUMN THAT CONTAINS AT LEAST 1% NULL\n",
    "null_percent = df.isnull().mean() * 100\n",
    "null_columns = null_percent[null_percent > 0]\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE COLUMNS WITH MORE THAN 5% NULL RATE AND SET NULL=0\n",
    "cols_to_fill = df.columns[df.isnull().mean() >= 0.05]\n",
    "df[cols_to_fill] = df[cols_to_fill].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN THE DATASET\n",
    "we need to take the data and transform it to a cleaner version, the final product must have a full numerical value dataset so that the model can understand it\n",
    "- `binary values`: yes/no to 1/0\n",
    "- `one-hot encoding`: nominal values will be replaced by similar binary values by the one-hot encoding method\n",
    "- `replace remaining nulls with mean`: the remaining nulls we did not erase are going to be replaced by means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY VALUES\n",
    "binary_map = {'Y': 1, 'N': 0}\n",
    "df['CentralAir'] = df['CentralAir'].map(binary_map)\n",
    "df['PavedDrive'] = df['PavedDrive'].map(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODING\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "bool_columns = [col for col in df.columns if df[col].apply(lambda x: str(x) in ['True', 'False']).all()]\n",
    "for col in bool_columns:\n",
    "    df[col] = df[col].apply(lambda x: 1 if str(x) == 'True' or x is True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE NULLS WITH MEAN\n",
    "numerical_columns = [col for col in df.columns if df[col].dtype in ['int64', 'float64'] and col not in bool_columns]\n",
    "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRELATION MATRIX\n",
    "we now have a load of collumns, lets see which ones are the ones worth keeping\n",
    "- `100% data`: too much data, unclear conclussions\n",
    "- `15% data`: very high correlation with price, can give us clear conclussions. 31 collumns remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE GENERAL CORRELATION MATRIX\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# too much data, nothing usefull to be seen here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE HIGHEST 20% OF VARIABLES WITH HIGHER CORRELATION TO PRICE\n",
    "corr_target = corr_matrix[\"SalePrice\"].abs().sort_values(ascending=False)\n",
    "selected_features = corr_target[:int(len(corr_target) * 1)].index.tolist()\n",
    "df_filtered = df[selected_features]\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(df_filtered.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Correlation Matrix of Selected Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT TO CSV\n",
    "df_filtered.to_csv(\"csv_files/02_filtered_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
